{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4cb3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/kirti/Dev/GenAI/E2EMedicalChatBotWithRAG/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5316c91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/kirti/Dev/GenAI/E2EMedicalChatBotWithRAG\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4e912e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-20 16:06:22,145|(INFO)| File: helper | Message: Loaded environment variable: GROQ_API_KEY]\n"
     ]
    }
   ],
   "source": [
    "from E2EMedicalChatBotWithRAG.models.llm_model import LLMAssistant\n",
    "llm_class = LLMAssistant()\n",
    "llm = llm_class.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "820c352b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/kirti/Dev/GenAI/E2EMedicalChatBotWithRAG/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "# import asyncio\n",
    "# from langchain.callbacks.streaming_aiter import AsyncIteratorCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1f26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # handler = AsyncIteratorCallbackHandler()\n",
    "\n",
    "# llm = ChatGroq(\n",
    "#             model=\"llama-3.1-8b-instant\",\n",
    "#             temperature=0.7,\n",
    "#             max_tokens=512,\n",
    "#             streaming=True \n",
    "#         #     callbacks=[handler]              # ðŸ”‘ enable streaming\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6193207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55d016d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/kirti/Dev/GenAI/E2EMedicalChatBotWithRAG\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b038d8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-20 16:42:49,234|(INFO)| File: SentenceTransformer | Message: Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2]\n",
      "[2025-09-20 16:45:37,167|(INFO)| File: embedding_model | Message: Successfully loaded embedding model: sentence-transformers/all-MiniLM-L6-v2]\n",
      "[2025-09-20 16:45:37,239|(INFO)| File: index | Message: Index already exists, not overwriting.]\n",
      "[2025-09-20 16:45:37,282|(INFO)| File: index | Message: Index already exists, not overwriting.]\n",
      "[2025-09-20 16:45:37,324|(WARNING)| File: redis_db | Message: Index medical-chatbot is empty or does not exist.]\n",
      "[2025-09-20 16:45:37,365|(INFO)| File: index | Message: Index already exists, not overwriting.]\n"
     ]
    }
   ],
   "source": [
    "from src.E2EMedicalChatBotWithRAG.vector_database.redis_db import RedisDB\n",
    "retriever = RedisDB().get_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3be14833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['RedisVectorStore', 'HuggingFaceEmbeddings'], vectorstore=<langchain_redis.vectorstores.RedisVectorStore object at 0x72d53780f830>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b9b1189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3deea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a helpful AI medical assistant that helps people find information.\n",
    "You are given the following extracted parts of a long document and a question. Provide a conversational answer\n",
    "based on the context provided.\n",
    "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "Always include relevant sources in your answer.\n",
    "Make sure the answer is in detail and more than 100 words.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "If the question is out of context, politely inform them that you are tuned to only answer questions that are related to the context.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7a786cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_prompt),\n",
    "                (\"user\", \"{input}\")\n",
    "            ]        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2a4e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "qna_chain =   prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62312ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever,\n",
    "    qna_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eb8ef9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'kirti pogra'}, page_content='This project is built by Kirti Pogra using LangChain, Pinecone and Groq. The code is available on GitHub. This project is only for educational purposes.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"what is acne?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "101dce63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-20 16:07:04,867|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"]\n",
      "I'm not sure if that's directly related to the context provided. The context is about a project built by Kirti Pogra using specific technologies, and the code is available on GitHub. However, I can try to provide a general answer about acne as it might be somewhat related to the human body, which might be implied in the context of someone who could be working on a health-related project.\n",
      "\n",
      "Acne is a common skin condition characterized by the occurrence of pimples, blackheads, and whiteheads. It is caused by a combination of factors, including:\n",
      "\n",
      "- Overproduction of sebum, an oily substance produced by the sebaceous glands in the skin\n",
      "- Blockage of the pores by dead skin cells and other debris\n",
      "- Bacteria buildup, specifically Propionibacterium acnes (P. acnes), which can cause inflammation and lead to acne lesions\n",
      "\n",
      "According to the American Academy of Dermatology (AAD), acne affects up to 50 million Americans each year, and it can occur at any age, from puberty to adulthood.\n",
      "\n",
      "However, to provide a more accurate and context-related answer, could you please provide more context or clarify how acne is related to the project mentioned in the text?"
     ]
    }
   ],
   "source": [
    "async for chunk in rag_chain.astream({\"input\": \"What is acne?\"}):\n",
    "    text = chunk.get('answer')\n",
    "    if text:\n",
    "        print(text.content, end=\"\",flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fbc5796",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def async_stream(query):\n",
    "    async for chunk in rag_chain.astream({\"input\": query}):\n",
    "        text = chunk.get('answer')\n",
    "        if text:\n",
    "            word = text.content\n",
    "            yield word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6afee0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming via astream_events:\n",
      "[2025-09-19 21:03:19,605|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"]\n",
      "Based on the provided context, the project was built by Kirti Pogra. According to the metadata, the project's source is listed as 'kirti pogra'. Additionally, the page content mentions that the project is built using LangChain, Pinecone, and Groq, and that the code is available on GitHub. This information suggests that Kirti Pogra is the developer behind this project, and it's intended for educational purposes."
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Streaming via astream_events:\")\n",
    "async for token in async_stream(\"who built this project?\"):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5749016",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_handler = ChatStreamingHandler()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4447740a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "E2EMedicalChatBotWithRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
