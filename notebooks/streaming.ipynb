{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4cb3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/kirti/Dev/GenAI/E2EMedicalChatBotWithRAG/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5316c91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/kirti/Dev/GenAI/E2EMedicalChatBotWithRAG\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace6d3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-24 21:00:52,016|(INFO)| File: helper | Message: Loaded environment variable: PINECONE_API_KEY]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/kirti/Dev/GenAI/E2EMedicalChatBotWithRAG/.venv/lib/python3.12/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "from src.E2EMedicalChatBotWithRAG.chains.rag_chain import RAGChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0f9f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RAGChain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e912e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-23 16:56:39,462|(INFO)| File: helper | Message: Loaded environment variable: GROQ_API_KEY]\n"
     ]
    }
   ],
   "source": [
    "from E2EMedicalChatBotWithRAG.models.llm_model import LLMAssistant\n",
    "llm_class = LLMAssistant()\n",
    "llm = llm_class.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6193207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b038d8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-23 16:56:46,226|(INFO)| File: helper | Message: Loaded environment variable: PINECONE_API_KEY]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/kirti/Dev/GenAI/E2EMedicalChatBotWithRAG/.venv/lib/python3.12/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-23 16:56:54,572|(INFO)| File: SentenceTransformer | Message: Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2]\n",
      "[2025-09-23 16:57:07,397|(INFO)| File: embedding_model | Message: Successfully loaded embedding model: sentence-transformers/all-MiniLM-L6-v2]\n"
     ]
    }
   ],
   "source": [
    "from src.E2EMedicalChatBotWithRAG.vectorestores.pinecone_db import PineconeDB\n",
    "sync_retriever = PineconeDB().get_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5cf33eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/kirti/Dev/GenAI/E2EMedicalChatBotWithRAG\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "906bd8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.pinecone_asyncio import PineconeAsyncio \n",
    "from src.E2EMedicalChatBotWithRAG.utils.helper import load_env_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be14833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-24 22:00:51,565|(INFO)| File: helper | Message: Loaded environment variable: PINECONE_API_KEY]\n"
     ]
    }
   ],
   "source": [
    "pinecone_api_key = load_env_variable(\"PINECONE_API_KEY\")\n",
    "pc = PineconeAsyncio(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b627ba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-24 22:01:02,244|(INFO)| File: helper | Message: Loaded environment variable: PINECONE_API_KEY]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/kirti/Dev/GenAI/E2EMedicalChatBotWithRAG/.venv/lib/python3.12/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-24 22:01:02,780|(INFO)| File: helper | Message: Loaded environment variable: GROQ_API_KEY]\n",
      "[2025-09-24 22:01:07,502|(INFO)| File: SentenceTransformer | Message: Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2]\n",
      "[2025-09-24 22:01:13,160|(INFO)| File: embedding_model | Message: Successfully loaded embedding model: sentence-transformers/all-MiniLM-L6-v2]\n"
     ]
    }
   ],
   "source": [
    "from src.E2EMedicalChatBotWithRAG.chains.rag_chain import RAGChain\n",
    "chain = await RAGChain.make_async(client=pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75d04242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-24 22:02:03,937|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"]\n",
      "The projectThe project was built by Kirti Pogra."
     ]
    }
   ],
   "source": [
    "async for token in chain.ainvoke(\"who build this project\"):\n",
    "        print(token, end=\"\", flush=True)  # live streaming in notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee6fc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "await pc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55ffa46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import PineconeAsyncio\n",
    "async def get_list_of_indexes():\n",
    "        index_list = await pc.list_indexes()\n",
    "        \n",
    "        return index_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fbfb1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_host_name(index_name):\n",
    "        index_info = await pc.describe_index(index_name)\n",
    "        host_name = index_info.host\n",
    "        return host_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c6afe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_indexes = await get_list_of_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f77b5ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_name = await get_host_name(\"medical-chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f6230a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'medical-chatbot-60n3d5q.svc.aped-4627-b74a.pinecone.io'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be39f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_index(host_name):\n",
    "    \"\"\"\n",
    "    You can find host name by calling get_list_of_indexes() function\n",
    "    \"\"\"\n",
    "    index = pc.IndexAsyncio(host=host_name)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc1af000",
   "metadata": {},
   "outputs": [],
   "source": [
    "async_index = await get_index(host_name=host_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2abda551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.db_data.index_asyncio._IndexAsyncio at 0x794b3018ffe0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f56d76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-24 17:56:26,302|(INFO)| File: SentenceTransformer | Message: Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2]\n",
      "[2025-09-24 17:56:32,828|(INFO)| File: embedding_model | Message: Successfully loaded embedding model: sentence-transformers/all-MiniLM-L6-v2]\n"
     ]
    }
   ],
   "source": [
    "from src.E2EMedicalChatBotWithRAG.models.embedding_model import EmbeddingModel\n",
    "embedding_model = EmbeddingModel()._get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d610d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, List, Optional\n",
    "from pydantic import PrivateAttr\n",
    "from langchain.schema import BaseRetriever, Document\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForRetrieverRun,\n",
    "    CallbackManagerForRetrieverRun,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5fd33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PineconeAsyncRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    A production-ready async retriever for Pinecone + HuggingFace embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embedding_model : Any\n",
    "        Must expose an `embed_query(text: str) -> List[float]` method.\n",
    "    index : Any\n",
    "        Pinecone index client with an async `query(...)` method.\n",
    "    k : int, default 3\n",
    "        Number of documents to retrieve.\n",
    "    search_kwargs : dict, optional\n",
    "        Extra parameters for Pinecone's query call.\n",
    "    tags : list[str], optional\n",
    "        Custom tags for observability/monitoring.\n",
    "    \"\"\"\n",
    "\n",
    "    _embedding_model: Any = PrivateAttr()\n",
    "    _index: Any = PrivateAttr()\n",
    "\n",
    "    k: int = 3\n",
    "    tags: Optional[List[str]] = None\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_model: Any,\n",
    "        index: Any,\n",
    "        k: int = 3,\n",
    "        tags: Optional[List[str]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self._embedding_model = embedding_model\n",
    "        self._index = index\n",
    "        self.k = k\n",
    "        self.tags = tags or [\"PineconeVectorStore\", \"HuggingFaceEmbeddings\"]\n",
    "\n",
    "    # Disable sync usage to force async pattern\n",
    "    def _get_relevant_documents(\n",
    "        self,\n",
    "        query: str,\n",
    "        *,\n",
    "        run_manager: CallbackManagerForRetrieverRun,\n",
    "    ) -> List[Document]:\n",
    "        raise NotImplementedError(\n",
    "            \"Synchronous retrieval is disabled. Use `aget_relevant_documents`.\"\n",
    "        )\n",
    "\n",
    "    async def _aget_relevant_documents(\n",
    "        self,\n",
    "        query: str,\n",
    "        *,\n",
    "        run_manager: AsyncCallbackManagerForRetrieverRun,\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Retrieve top-k documents asynchronously from Pinecone.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of langchain.schema.Document\n",
    "        \"\"\"\n",
    "        # 1. Embed the query\n",
    "        try:\n",
    "            query_vector = self._embedding_model.embed_query(query)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Embedding failed: {e}\") from e\n",
    "\n",
    "        # 2. Query Pinecone\n",
    "        try:\n",
    "            response = await self._index.query(\n",
    "                vector=query_vector,\n",
    "                top_k=self.k,\n",
    "                include_metadata=True,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Pinecone query failed: {e}\") from e\n",
    "\n",
    "        # 3. Build Document list\n",
    "        documents: List[Document] = []\n",
    "        for match in response.get(\"matches\", []):\n",
    "            metadata = match.get(\"metadata\", {})\n",
    "            text = metadata.get(\"text\")\n",
    "            if not text:\n",
    "                continue  # Skip if no text found\n",
    "            documents.append(\n",
    "                Document(\n",
    "                    page_content=text,\n",
    "                    metadata={\n",
    "                        \"source\": metadata.get(\"source\"),\n",
    "                        \"similarity_score\": match.get(\"score\"),\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f511cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "async_retriever = PineconeAsyncRetriever(embedding_model=embedding_model, index=async_index, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc92fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async_response = await async_retriever.ainvoke(\"what is acne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8b327f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/Medical_book.pdf', 'similarity_score': 0.663705826}, page_content='The goal of treating moderate acne is to decrease\\ninflammation and prevent new comedone formation. One\\neffective treatment is topical tretinoin along with a topical\\nGALE ENCYCLOPEDIA OF MEDICINE 2 25\\nAcne\\nAcne vulgaris affecting a woman’s face. Acne is the general\\nname given to a skin disorder in which the sebaceous\\nglands become inflamed. (Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
       " Document(metadata={'source': 'data/Medical_book.pdf', 'similarity_score': 0.636904716}, page_content='Description\\nAcne vulgaris, the medical term for common acne, is\\nthe most common skin disease. It affects nearly 17 million\\npeople in the United States. While acne can arise at any\\nage, it usually begins at puberty and worsens during ado-\\nlescence. Nearly 85% of people develop acne at some time\\nbetween the ages of 12-25 years. Up to 20% of women\\ndevelop mild acne. It is also found in some newborns.\\nThe sebaceous glands lie just beneath the skin’s sur-\\nface. They produce an oil called sebum, the skin’s natural\\nmoisturizer. These glands and the hair follicles within\\nwhich they are found are called sebaceous follicles.\\nThese follicles open onto the skin through pores. At\\npuberty, increased levels of androgens (male hormones)\\ncause the glands to produce too much sebum. When\\nexcess sebum combines with dead, sticky skin cells, a\\nhard plug, or comedo, forms that blocks the pore. Mild\\nnoninflammatory acne consists of the two types of come-\\ndones, whiteheads and blackheads.'),\n",
       " Document(metadata={'source': 'data/Medical_book.pdf', 'similarity_score': 0.623968184}, page_content='tranquilizers, antidepressants, antibiotics, oral contra-\\nceptives, and anabolic steroids.\\n• Personal hygiene. Abrasive soaps, hard scrubbing, or\\npicking at pimples will make them worse.\\n• Cosmetics. Oil-based makeup and hair sprays worsen\\nacne.\\n• Environment. Exposure to oils and greases, polluted air,\\nand sweating in hot weather aggravate acne.\\n• Stress. Emotional stress may contribute to acne.\\nAcne is usually not conspicuous, although inflamed\\nlesions may cause pain, tenderness, itching, or swelling.\\nThe most troubling aspects of these lesions are the nega-\\ntive cosmetic effects and potential for scarring. Some\\npeople, especially teenagers, become emotionally upset\\nabout their condition, and have problems forming rela-\\ntionships or keeping jobs.\\nDiagnosis\\nAcne patients are often treated by family doctors.\\nComplicated cases are referred to a dermatologist, a skin\\nGALE ENCYCLOPEDIA OF MEDICINE 224\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 24')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851883a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For synchronous calls, we already have sync_retriever from PineconeDB class\n",
    "sync_response = sync_retriever.invoke(\"what is acne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8094c02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='05b4dceb-33ab-4aca-8e0d-86398d62862c', metadata={'source': 'data/Medical_book.pdf'}, page_content='The goal of treating moderate acne is to decrease\\ninflammation and prevent new comedone formation. One\\neffective treatment is topical tretinoin along with a topical\\nGALE ENCYCLOPEDIA OF MEDICINE 2 25\\nAcne\\nAcne vulgaris affecting a woman’s face. Acne is the general\\nname given to a skin disorder in which the sebaceous\\nglands become inflamed. (Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
       " Document(id='c48a9784-043a-49c8-8492-5ea87845ea8d', metadata={'source': 'data/Medical_book.pdf'}, page_content='Description\\nAcne vulgaris, the medical term for common acne, is\\nthe most common skin disease. It affects nearly 17 million\\npeople in the United States. While acne can arise at any\\nage, it usually begins at puberty and worsens during ado-\\nlescence. Nearly 85% of people develop acne at some time\\nbetween the ages of 12-25 years. Up to 20% of women\\ndevelop mild acne. It is also found in some newborns.\\nThe sebaceous glands lie just beneath the skin’s sur-\\nface. They produce an oil called sebum, the skin’s natural\\nmoisturizer. These glands and the hair follicles within\\nwhich they are found are called sebaceous follicles.\\nThese follicles open onto the skin through pores. At\\npuberty, increased levels of androgens (male hormones)\\ncause the glands to produce too much sebum. When\\nexcess sebum combines with dead, sticky skin cells, a\\nhard plug, or comedo, forms that blocks the pore. Mild\\nnoninflammatory acne consists of the two types of come-\\ndones, whiteheads and blackheads.'),\n",
       " Document(id='596a63c4-8639-46c5-a339-f4a85b455572', metadata={'source': 'data/Medical_book.pdf'}, page_content='tranquilizers, antidepressants, antibiotics, oral contra-\\nceptives, and anabolic steroids.\\n• Personal hygiene. Abrasive soaps, hard scrubbing, or\\npicking at pimples will make them worse.\\n• Cosmetics. Oil-based makeup and hair sprays worsen\\nacne.\\n• Environment. Exposure to oils and greases, polluted air,\\nand sweating in hot weather aggravate acne.\\n• Stress. Emotional stress may contribute to acne.\\nAcne is usually not conspicuous, although inflamed\\nlesions may cause pain, tenderness, itching, or swelling.\\nThe most troubling aspects of these lesions are the nega-\\ntive cosmetic effects and potential for scarring. Some\\npeople, especially teenagers, become emotionally upset\\nabout their condition, and have problems forming rela-\\ntionships or keeping jobs.\\nDiagnosis\\nAcne patients are often treated by family doctors.\\nComplicated cases are referred to a dermatologist, a skin\\nGALE ENCYCLOPEDIA OF MEDICINE 224\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 24')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sync_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3deea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a helpful AI medical assistant that helps people find information.\n",
    "You are given the following extracted parts of a long document and a question. Provide a conversational answer\n",
    "based on the context provided.\n",
    "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "Always include relevant sources in your answer.\n",
    "Make sure the answer is in detail and more than 100 words.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "If the question is out of context, politely inform them that you are tuned to only answer questions that are related to the context.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f7a786cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_prompt),\n",
    "                (\"user\", \"{input}\")\n",
    "            ]     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf349421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "async_chain = (\n",
    "    {\n",
    "        \"context\": async_retriever,          # Pinecone search → returns docs\n",
    "        \"input\": RunnablePassthrough()  # pass the raw user query\n",
    "    }\n",
    "    | prompt\n",
    "    | llm \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72a1fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_chain = (\n",
    "    {\n",
    "        \"context\": sync_retriever,          # Pinecone search → returns docs\n",
    "        \"input\": RunnablePassthrough()  # pass the raw user query\n",
    "    }\n",
    "    | prompt\n",
    "    | llm  # ChatOpenAI(streaming=True) etc.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59313bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def stream_answer(query):\n",
    "    # Keep the client alive during streaming\n",
    "    async for token in async_chain.astream(query):\n",
    "        print(token.content, end=\"\", flush=True)  # live streaming in notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "301cc4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-23 17:20:51,842|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"]\n",
      "Based on the provided context, the project was built by Kirti Pogra using LangChain, Pinecone, and Groq. The code for this project is available on GitHub, and it is for educational purposes only."
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "await stream_answer(\"who build this project\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f1ab5bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-23 17:21:02,003|(INFO)| File: _client | Message: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"]\n",
      "Based on the provided context, it appears that the project was built by Kirti Pogra. This information is mentioned in the first document (id='602d3e94-ceaa-46db-847e-c6cbf92d42df') which states: \"This project is built by Kirti Pogra using LangChain, Pinecone and Groq.\"\n",
      "\n",
      "The project is also mentioned to be available on GitHub, but no further information is provided about the project itself. \n",
      "\n",
      "Source: Document(id='602d3e94-ceaa-46db-847e-c6cbf92d42df')"
     ]
    }
   ],
   "source": [
    "for token in sync_chain.stream(\"who build this project?\"):\n",
    "    print(token.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6572c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "await pc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca20bb25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "E2EMedicalChatBotWithRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
